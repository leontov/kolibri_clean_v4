# Мультимодальное ядро Kolibri-x

> Ответственный: Кочуров Владислав Евгеньевич. Обновляйте документ при
> изменении архитектуры или процессов обучения мультимодального ядра.

## Цели
- Объединить текст, визуальные, аудио и сенсорные сигналы в реактивном ядре с
  минимальной задержкой.
- Обеспечить адаптацию вычислений под контекст (модальность, устройство,
  энергетические ограничения).
- Создать безопасный конвейер непрерывного обучения без катастрофического
  забывания.

## 1. Адаптивный трансформер с перекрёстным вниманием
- **Компоненты:**
  - `DynamicDepthController` — вычисляет глубину слоёв на основе входных
    сигналов (энергия устройства, важность модальности, SLA по задержке).
  - `CrossModalAttention` — матрица внимания, связывающая токены разных
    модальностей; поддерживает sparse kernel для длинных последовательностей.
  - `LatencyMonitor` — телеметрия на уровне слоя, передаётся в оркестратор для
    live-тюнинга параметров.
- **Алгоритм:**
  1. Фьюжн-трансформер собирает токены от энкодеров.
  2. Контроллер оценивает budget и выбирает глубину по модальности (например,
     6 слоёв для видео, 4 для речи, 2 для текста на Edge).
  3. Внимание рассчитывается попарно с использованием динамических масок;
     межмодальные связи получают приоритет на ранних слоях.
  4. На каждом шаге монитор задержки корректирует глубину для следующих батчей.
- **Реализация:** Python-прототип в `kolibri_x/core/transformer.py`, C++/CUDA
  блоки для продакшен-версии. Состояние слоя кэшируется для итеративных
  запросов одной сессии.

## 2. Диффузионный визуальный энкодер с онлайновой токенизацией
- **Цель:** компрессия видеопотоков в семантически насыщенные токены без
  потери деталей действий/объектов.
- **Архитектура:**
  - Диффузионный автоэнкодер (3D U-Net) с латентным пространством 32×
    сжатия.
  - `OnlineTokenizer` — обновляет кодовые книги в реальном времени, поддерживая
    sliding window и dropout редких токенов.
  - Выход подаётся в `CrossModalAttention` с метаданными (камера, сцена).
- **Интеграция:** компонент размещается в `kolibri_x/core/vision.py`, а веса
  хранятся в отдельном репозитории артефактов. Для low-power устройств
  предусмотрен fallback на ключевые кадры (1 fps) + объектные детекции.

## 3. Аудиоэнкодер с самокалибровкой шума
- **Функции:**
  - `NoiseProfiler` собирает статистику фона, обновляет пороги VAD.
  - `SpeakerAdaptor` строит голосовой профиль пользователя (pitch, timbre,
    speaking rate) и подстраивает нормализацию.
  - `MultiResolutionConformer` применяет несколько окон FFT (10/25/50 мс) с
    вниманием между масштабами.
- **Пайплайн:** raw аудио → шумоподавление (RNNoise) → многооконный спектр →
  Conformer → эмбеддинги для трансформера. Профили пользователей хранятся в
  приватном сегменте профайлера (см. `kolibri_x/personalization`).

## 4. Сенсорный хаб IoT
- **Компоненты:**
  - `SensorEventBus` — gRPC/WebSocket-шина для приёма событий от устройств.
  - `SensorSchemaRegistry` — описания типов событий (температура, гео, жесты).
  - `SensorNormalizer` — приводит данные к унифицированному
    событие-представлению `{ts, modality, entity, value, confidence}`.
- **Встраивание:** события преобразуются в токены `SensorToken` и подаются в
  трансформер через отдельный порт с приоритетом по SLA (alarm > telemetry).
  События с низкой уверенностью помечаются для последующей очистки.

## 5. Мультимодальное согласование времени
- **Задача:** синхронно совмещать речь, жесты, визуальные подсказки и сенсорные
  события.
- **Решение:**
  - `TemporalAligner` — центральный модуль с буфером 200 мс, использует
    Dynamic Time Warping + attention alignment loss при обучении.
  - `SyncMarkers` — метки из голосового и визуального потоков (фонемы,
    ключевые кадры) для точной синхронизации.
  - При расхождении >100 мс запускается коррекция (растягивание/сжатие)
    подсказок и переигровка жестов.
- **Интеграция:** выравнивание происходит до попадания токенов в трансформер и
  при генерации ответов (асинхронный адаптер для подсказок).

## 6. Адаптивный компилятор модальностей
- **Назначение:** выбирать минимально необходимую подсеть для заданных целей и
  ограничений устройства.
- **Архитектура:**
  - `ModalityCompiler` анализирует требования (точность, задержка, батарея) и
    строит граф исполнения из блоков (`VideoHiRes`, `AudioLowRes`, `SensorFast`).
  - `CostModel` оценивает энергопотребление и latency для каждого блока.
  - `PolicyEngine` использует правила и reinforcement signals (QoS) для
    переключения.
- **Результат:** оркестратор получает план вычислений, а трансформер включается
  в соответствующем режиме (например, отключить высокие слои видео, но оставить
  аудио на полной глубине).

## 7. Непрерывное дообучение
- **Поток данных:**
  - Синтетические задачи генерируются симуляторами (жесты, шумовые сценарии,
    мультимодальные Q/A) → попадают в `ContinualTrainer`.
  - Используется методика Elastic Weight Consolidation + Replay Buffer на
    критичных примерах.
  - Проверки катастрофического забывания выполняются в `tests/eval_continual`
    (будущий набор тестов).
- **Операции:** раз в сутки запускается офлайн-дообучение, артефакты версионируют
  (MLflow/Weights & Biases). Перед выкладкой проходит sandbox-тренировка на
  выделенном кластере Edge для оценки переносимости.
- **Online AL-петля:**
  - `BackgroundSelfLearner` ведёт EWMA-дрейф по статусам исполнения навыков.
    При превышении порога формируется отчёт `self_learning_report` в
    `ActionJournal` и метка деградации в runtime.
  - `KolibriRuntime` инициирует запрос дополнительных примеров, добавляя событие
    `self_learning_degradation` с семплами и последним апдейтом весов. Список
    активных запросов доступен через `pending_example_requests()`.
  - Аннотаторы выгружают контрпримеры методом `upload_counterexamples()`, что
    автоматически публикует `self_learning_counterexamples` и повторно запускает
    оценку дрейфа.

## 8. Контекстное переключение разрешения
- **Компоненты:**
  - `UtilityPredictor` — ML-модель, оценивающая полезность высоких/низких
    разрешений по текущему контексту (тип задачи, качество входа, важность).
  - `ResolutionRouter` — использует прогноз, чтобы выбирать профили
    энкодеров (`video_hi`, `video_lo`, `audio_full`, `audio_sparse`).
  - `FeedbackLoop` — собирает качество (mKSI, MOS) и корректирует веса модели.
- **Применение:** при голосовых задачах без визуала видео переключается в low
  fps; при критических IoT алармах активируется full-stack визуал + haptic.
  Решения логируются для аудита и оптимизации стоимости.

## Интеграция в существующую архитектуру
- Обновлённый трансформер и сопутствующие модули размещаются в `kolibri_x/core`
  с интерфейсом `FusionCore`, совместимым с `KolibriRuntime`.
- Сенсорный хаб подключается к `kolibri_x/runtime/iot.py`, использует единые
  политики приватности (`PrivacyOperator`).
- Политики переключения и профили пользователей синхронизируются с
  `kolibri_x/personalization` и `configs/kolibri.json`.

## План внедрения
| Этап | Недели | Основные задачи | Выходы |
| --- | --- | --- | --- |
| **M0 — Подготовка** | 1–2 | Прототип DynamicDepthController, онлайновая токенизация, сбор датасетов | Демонстрационные ноутбуки, синтетические данные |
| **M1 — Базовая интеграция** | 3–6 | Внедрение трансформера, аудио/видео энкодеров, TemporalAligner | `FusionCore` в рантайме, первые метрики latency |
| **M2 — Компилятор и сенсорный хаб** | 7–9 | ModalityCompiler, SensorEventBus, политики приватности | Edge-профили, SLA для IoT |
| **M3 — Непрерывное обучение** | 10–12 | ContinualTrainer, UtilityPredictor, автоматические тесты | Отчёты по забыванию, переключение разрешений |

## Метрики успеха
- **Latency:** аудио-текст ≤ 250 мс end-to-end, визуал ≤ 800 мс для ключевого
  кадра.
- **Качество:** mKSI-G ≥ 0.75 на мультимодальных миссиях, MOS ≥ 4.0.
- **Экономия энергии:** ≥ 30% снижение потребления на Edge при сохранении
  точности (сравнение с полным стеком).
- **Устойчивость:** забывание < 2% при непрерывном обучении на 30 дневных
  циклах.

## Зависимости и риски
- Требуется обновление безопасного хранилища весов и политик доступа.
- Высокая стоимость вычислений диффузионного энкодера — обязательна поддержка
  low-res fallback.
- Профили пользователей подпадают под требования приватности — обязателен
  opt-in и локальное хранение с шифрованием.

